{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdcb927-d41d-4262-92a9-8db9ce0162bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d183d88-7d17-4bf4-acb5-1d0b96fe6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=400, n_features=4)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767902a-4028-49c9-b4d0-ef3506c77133",
   "metadata": {},
   "source": [
    "##### Добавляем регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b796a74b-adce-492d-bab6-d720ea2c0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg():\n",
    "    def __init__(self, n_iter=10, learning_rate=0.1, reg=None, l1_coef=0, l2_coef=0, metric=None, weights=None):\n",
    "        self.n_iter = n_iter \n",
    "        self.learning_rate = learning_rate\n",
    "        self.__weights = weights\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.__best_score = None\n",
    "\n",
    "        self.__validate_params()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "\n",
    "    def __validate_params(self):\n",
    "        \"\"\"Проверяет корректность параметров модели.\"\"\"\n",
    "        if self.metric is not None and self.metric not in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            raise ValueError(f\"Invalid metric: {self.metric}, You can only use: 'accuracy', 'precision', 'recall', 'f1' or 'roc_auc' \")\n",
    "        # Проверям на входные параметры регулиризации \n",
    "        if self.reg is not None and self.reg not in ['l1', 'l2', 'elasticnet']:\n",
    "            raise ValueError(\"reg must be 'l1', 'l2', or 'elasticnet'\")\n",
    "        # Проверка коэффициентов (должны быть от 0 до 1)\n",
    "        if self.l1_coef < 0 or self.l1_coef > 1:\n",
    "            raise ValueError(\"l1_coef must be in [0, 1]\")\n",
    "        if self.l2_coef < 0 or self.l2_coef > 1:\n",
    "            raise ValueError(\"l2_coef must be in [0, 1]\")\n",
    "    \n",
    "    def __log_training_step(self, iteration: int, y: np.array, proba: np.array, w: np.array):\n",
    "        \"\"\"Логирует процесс обучения (итерацию, веса, функцию потерь).\n",
    "    \n",
    "        Параметры:\n",
    "        iteration: int - номер итерации\n",
    "        X: np.array - матрица признаков\n",
    "        y: np.array - вектор истинных меток (0 или 1)\n",
    "        proba: np.array - предсказанные вероятности класса 1\n",
    "        \"\"\"\n",
    "        loss = self.__calculate_loss(y, proba, w)                           # считаем loss \n",
    "        metric_value = None                                                 # Инициализируем метрикику \n",
    "        if self.metric:                                                     # если она задана \n",
    "            y_pred = (proba>0.5).astype(int)                                # вероятности переводим в метки\n",
    "            metric_value = self.__calculat_metric(y, y_pred if self.metric != 'roc_auc' else proba)       # cчитаем метрику\n",
    "            \n",
    "        if iteration == 0:\n",
    "            if self.metric:\n",
    "                print(f'start | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'start | loss: {loss:0.2f}')\n",
    "        else:\n",
    "            if self.metric:\n",
    "                print(f'{iteration} | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'{iteration} | loss: {loss:0.2f}')\n",
    "\n",
    "    def __calculate_loss(self, y: np.array, proba: np.array, w: np.array) -> float:\n",
    "        \"\"\"\n",
    "        Вычисляем общий loss (MSLE + регуляризация).\n",
    "        X: np.array (Матрица признаков)\n",
    "        y: np.array (Вектор значений)\n",
    "        w: np.array (Вектор весов)\n",
    "        \"\"\"\n",
    "        eps = 1e-15\n",
    "        loss = -np.mean(y*np.log(proba+eps) + (1-y)*(np.log(1-proba+eps)))\n",
    "\n",
    "        if self.reg == 'l1':\n",
    "            return loss + self.l1_coef * np.sum(np.abs(w))\n",
    "        elif self.reg == 'l2':\n",
    "            return loss + self.l2_coef * np.sum(w**2)\n",
    "        elif self.reg == 'elasticnet':\n",
    "            return loss + self.l1_coef * np.sum(np.abs(w)) + self.l2_coef * np.sum(w**2)\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def __apply_regularization(self, grad: np.array, w: np.array):\n",
    "        \"\"\"Добавляет градиент регуляризации.\"\"\"\n",
    "        if self.reg == 'l1':\n",
    "            return grad + self.l1_coef * np.sign(w)\n",
    "        elif self.reg == 'l2':\n",
    "            return grad + 2 * self.l2_coef * w\n",
    "        elif self.reg == 'elasticnet':\n",
    "            return grad + self.l1_coef * np.sign(w) + 2 * self.l2_coef * w\n",
    "        else:\n",
    "            return grad\n",
    "    \n",
    "    def __calculat_metric(self, y_true: np.array, y_pred: np.array):\n",
    "        \"\"\"Считает заданные метрики.\"\"\"\n",
    "        #  Напишем функцию для подсчета матрицы ошибок\n",
    "        def confusion_matrix(y_true: np.array, y_pred: np.array):\n",
    "            # инициализируем нашу матрицу ошибок\n",
    "            tn = fn = fp = tp = 0 \n",
    "            for true, pred in zip(y_true, y_pred):\n",
    "                if pred == 0 and true == 0:          # TN\n",
    "                    tn += 1 \n",
    "                elif pred == 0 and true == 1:        # FN\n",
    "                    fn += 1 \n",
    "                elif pred == 1 and true == 0:        # FP\n",
    "                    fp += 1 \n",
    "                elif pred == 1 and true == 1:        # TP\n",
    "                    tp += 1 \n",
    "            return tn, fn, fp, tp\n",
    "        \n",
    "        if self.metric == 'roc_auc':\n",
    "            # Предсказанные вероятности\n",
    "            y_scores = y_pred\n",
    "            # Сортируем по вероятностям\n",
    "            sorted_indices = np.argsort(y_scores)\n",
    "            sorted_y = np.array(y_true)[sorted_indices]\n",
    "\n",
    "            # Присваиваем ранги (от 1 до n, как в scipy)\n",
    "            n = len(y_scores)\n",
    "            ranks = np.empty(n)\n",
    "            i = 0\n",
    "            while i < n:\n",
    "                j = i\n",
    "                while j + 1 < n and y_scores[sorted_indices[j]] == y_scores[sorted_indices[j + 1]]:\n",
    "                    j += 1\n",
    "                avg_rank = (i + j + 2) / 2  # т.к. ранги начинаются с 1\n",
    "                for k in range(i, j + 1):\n",
    "                    ranks[k] = avg_rank\n",
    "                i = j + 1\n",
    "\n",
    "            # Считаем сумму рангов положительного класса\n",
    "            sum_ranks_pos = np.sum(ranks[sorted_y == 1])\n",
    "\n",
    "            P = np.sum(sorted_y)         # количество положительных\n",
    "            N = n - P                    # количество отрицательных\n",
    "\n",
    "            if P == 0 or N == 0:\n",
    "                return None\n",
    "            # Вычисляем AUC по формуле Манна-Уитни\n",
    "            auc = (sum_ranks_pos - P * (P + 1) / 2) / (P * N)\n",
    "            return auc\n",
    "        \n",
    "        tn, fn, fp, tp = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        if self.metric == 'accuracy':\n",
    "            return (tp + tn) / (tp + tn + fp + fn)\n",
    "        elif self.metric == 'precision':\n",
    "            return tp / (tp + fp)\n",
    "        elif self.metric == 'recall':\n",
    "            return tp / (tp + fn)\n",
    "        elif self.metric == 'f1':\n",
    "            pr = tp / (tp + fp)      # precision\n",
    "            re = tp / (tp + fn)      # recall\n",
    "            return (2*pr*re) / (pr + re)\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose=False):\n",
    "        \"\"\"\n",
    "        Метод обучает модель Логистической регресси \n",
    "        Входные параметры:\n",
    "        X: pd.DataFrame\n",
    "        y: pd.Series\n",
    "        verbose: bool\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()                                       # копируем матрицу признаков, чтобы не изменить оригинальный \n",
    "        X_copy.insert(0, 'base', 1)                             # добавляем столбик для свободного члена, заполним его 1\n",
    "        X_copy = X_copy.to_numpy()  \n",
    "        self.__weights = np.ones(X_copy.shape[1])               # создаем вектор весов, заполненный 1\n",
    "\n",
    "        # Цикл обучения\n",
    "        for i in range(self.n_iter):\n",
    "            pred = X_copy.dot(self.__weights)                   # делаем предсказание модели\n",
    "            proba = 1 / (1 + np.exp(-pred))                     # переводим предсказания в вероятности через функцию сигмоиды\n",
    "            grad = (1/len(y))*(proba - y).dot(X_copy)           # вычисляем градиент LogLoss\n",
    "            grad = self.__apply_regularization(grad, self.__weights)   # добавляем регуляризацию\n",
    "            #self.__weights -= self.learning_rate * grad        # делаем шаг обучения\n",
    "            if self.metric:                                    # если задана метрика \n",
    "                if i == self.n_iter-1:                         # считаем его на n - 1 итерации, чтобы последнне значение записать в best_score\n",
    "                    marks = (proba>0.5).astype(int)\n",
    "                    self.__best_score = self.__calculat_metric(y_true=y, y_pred=marks if self.metric!='roc_auc' else proba)\n",
    "\n",
    "            if verbose and (i % 10 == 0 or i == self.n_iter-1):\n",
    "                self.__log_training_step(i, y, proba, self.__weights)\n",
    "\n",
    "            self.__weights -= self.learning_rate * grad          # делаем шаг обучения\n",
    "            \n",
    "    def predict_proba(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет вероятностное предсказание модели\"\"\"\n",
    "        X_copy = X.copy()\n",
    "        X_copy.insert(0, 'base', 1)\n",
    "        pred = X_copy.dot(self.__weights)\n",
    "        proba = 1 / (1 + np.exp(-pred))\n",
    "        return np.array(proba)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет маркерное предсказание модели\"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.array((proba > 0.5).astype(int))\n",
    "\n",
    "    def get_best_score(self):\n",
    "        if self.metric is None:\n",
    "            raise ValueError(\"Metric was not set during model initialization.\")\n",
    "        return self.__best_score\n",
    "                \n",
    "    def get_coef(self) -> np.array:\n",
    "        return np.array(self.__weights[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc33a79-428a-4b3d-97d4-cb4e34a56bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c21cece0-5001-4f78-915c-be8fa05f0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLogReg(reg='elasticnet', l1_coef=0.4, l2_coef=0.45, n_iter=100, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "68ec89d6-6396-491b-b132-efb3f6db6d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e62baaac-9b38-44e9-bf11-84714fb53a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 5.06 | accuracy: 0.50\n",
      "10 | loss: 0.88 | accuracy: 0.87\n",
      "20 | loss: 0.72 | accuracy: 0.86\n",
      "30 | loss: 0.72 | accuracy: 0.85\n",
      "40 | loss: 0.72 | accuracy: 0.84\n",
      "50 | loss: 0.72 | accuracy: 0.85\n",
      "60 | loss: 0.72 | accuracy: 0.85\n",
      "70 | loss: 0.72 | accuracy: 0.85\n",
      "80 | loss: 0.72 | accuracy: 0.85\n",
      "90 | loss: 0.72 | accuracy: 0.85\n",
      "99 | loss: 0.72 | accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7b8e8574-0176-4e0c-9537-7eb9034f44a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0150875 ,  0.0254203 ,  0.04912361, -0.03112845])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "051b1d38-c469-4183-a6ea-2e6164e5b343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLogReg class: n_iter=100, learning_rate=0.1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fbd8a-f68b-4aae-9a66-2fdedf841abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c5d46-434a-4b29-8ebf-983aa54e2a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
