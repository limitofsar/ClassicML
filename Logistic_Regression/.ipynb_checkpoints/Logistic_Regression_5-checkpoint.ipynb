{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdcb927-d41d-4262-92a9-8db9ce0162bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d183d88-7d17-4bf4-acb5-1d0b96fe6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=400, n_features=4)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "696ca46d-2434-499b-9407-9f6ef13b19fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.914741</td>\n",
       "      <td>-1.349410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.568828</td>\n",
       "      <td>-0.078698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533364</td>\n",
       "      <td>-1.442710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.767586</td>\n",
       "      <td>-0.603153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f2        f3\n",
       "0 -2.914741 -1.349410\n",
       "1 -0.568828 -0.078698\n",
       "2  0.533364 -1.442710\n",
       "3 -1.767586 -0.603153"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[0:4, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b796a74b-adce-492d-bab6-d720ea2c0eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyLogReg\u001b[39;00m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m n_iter \n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mMyLogReg\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid metric: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, You can only use: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__log_training_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, X: np\u001b[38;5;241m.\u001b[39marray, y: np\u001b[38;5;241m.\u001b[39marray, proba: np\u001b[38;5;241m.\u001b[39marray):\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Логирует процесс обучения (итерацию, веса, функцию потерь).\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    Параметры:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    proba: np.array - предсказанные вероятности класса 1\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     eps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-15\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "class MyLogReg():\n",
    "    def __init__(self, n_iter=10, learning_rate=0.1, metric=None, weights=None):\n",
    "        self.n_iter = n_iter \n",
    "        self.learning_rate = learning_rate\n",
    "        self.__weights = weights\n",
    "        self.metric = metric\n",
    "        self.__best_score = None\n",
    "\n",
    "        self.__validate_params()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "\n",
    "    def __validate_params(self):\n",
    "        \"\"\"Проверяет корректность параметров модели.\"\"\"\n",
    "        if self.metric is not None and self.metric not in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            raise ValueError(f\"Invalid metric: {self.metric}, You can only use: 'accuracy', 'precision', 'recall', 'f1' or 'roc_auc' \")\n",
    "    \n",
    "    def __log_training_step(self, iteration: int, X: np.array, y: np.array, proba: np.array):\n",
    "        \"\"\"Логирует процесс обучения (итерацию, веса, функцию потерь).\n",
    "    \n",
    "        Параметры:\n",
    "        iteration: int - номер итерации\n",
    "        X: np.array - матрица признаков\n",
    "        y: np.array - вектор истинных меток (0 или 1)\n",
    "        proba: np.array - предсказанные вероятности класса 1\n",
    "        \"\"\"\n",
    "        eps = 1e-15\n",
    "        loss = -np.mean(y*np.log(proba+eps) + (1-y)*(np.log(1-proba+eps)))\n",
    "        metric_value = None                                                 # Инициализируем метрикику \n",
    "        if self.metric:                                                     # если она задана \n",
    "            y_pred = (proba>0.5).astype(int)                                # вероятности переводим в метки\n",
    "            metric_value = self.__calculat_metric(y, y_pred if self.metric != 'roc_auc' else proba)       # cчитаем метрику\n",
    "            \n",
    "        if iteration == 0:\n",
    "            if self.metric:\n",
    "                print(f'start | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'start | loss: {loss:0.2f}')\n",
    "        else:\n",
    "            if self.metric:\n",
    "                print(f'{iteration} | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'{iteration} | loss: {loss:0.2f}')\n",
    "    def __calculat_metric(self, y_true: np.array, y_pred: np.array):\n",
    "        \"\"\"\n",
    "        Считает заданные метрики\n",
    "        \"\"\"\n",
    "        #  Напишем функцию для подсчета матрицы ошибок\n",
    "        def confusion_matrix(y_true: np.array, y_pred: np.array):\n",
    "            # инициализируем нашу матрицу ошибок\n",
    "            tn = fn = fp = tp = 0 \n",
    "            for true, pred in zip(y_true, y_pred):\n",
    "                if pred == 0 and true == 0:          # TN\n",
    "                    tn += 1 \n",
    "                elif pred == 0 and true == 1:        # FN\n",
    "                    fn += 1 \n",
    "                elif pred == 1 and true == 0:        # FP\n",
    "                    fp += 1 \n",
    "                elif pred == 1 and true == 1:        # TP\n",
    "                    tp += 1 \n",
    "            return tn, fn, fp, tp\n",
    "        \n",
    "        if self.metric == 'roc_auc':\n",
    "            # Предсказанные вероятности\n",
    "            y_scores = y_pred\n",
    "            # Сортируем по вероятностям\n",
    "            sorted_indices = np.argsort(y_scores)\n",
    "            sorted_y = np.array(y_true)[sorted_indices]\n",
    "\n",
    "            # Присваиваем ранги (от 1 до n, как в scipy)\n",
    "            n = len(y_scores)\n",
    "            ranks = np.empty(n)\n",
    "            i = 0\n",
    "            while i < n:\n",
    "                j = i\n",
    "                while j + 1 < n and y_scores[sorted_indices[j]] == y_scores[sorted_indices[j + 1]]:\n",
    "                    j += 1\n",
    "                avg_rank = (i + j + 2) / 2  # т.к. ранги начинаются с 1\n",
    "                for k in range(i, j + 1):\n",
    "                    ranks[k] = avg_rank\n",
    "                i = j + 1\n",
    "\n",
    "            # Считаем сумму рангов положительного класса\n",
    "            sum_ranks_pos = np.sum(ranks[sorted_y == 1])\n",
    "\n",
    "            P = np.sum(sorted_y)         # количество положительных\n",
    "            N = n - P                    # количество отрицательных\n",
    "\n",
    "            if P == 0 or N == 0:\n",
    "                return None\n",
    "            # Вычисляем AUC по формуле Манна-Уитни\n",
    "            auc = (sum_ranks_pos - P * (P + 1) / 2) / (P * N)\n",
    "            return auc\n",
    "\n",
    "        \n",
    "        tn, fn, fp, tp = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        if self.metric == 'accuracy':\n",
    "            return (tp + tn) / (tp + tn + fp + fn)\n",
    "        elif self.metric == 'precision':\n",
    "            return tp / (tp + fp)\n",
    "        elif self.metric == 'recall':\n",
    "            return tp / (tp + fn)\n",
    "        elif self.metric == 'f1':\n",
    "            pr = tp / (tp + fp)      # precision\n",
    "            re = tp / (tp + fn)      # recall\n",
    "            return (2*pr*re) / (pr + re)\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose=False):\n",
    "        \"\"\"\n",
    "        Метод обучает модель Логистической регресси \n",
    "        Входные параметры:\n",
    "        X: pd.DataFrame\n",
    "        y: pd.Series\n",
    "        verbose: bool\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()                                     # копируем матрицу признаков, чтобы не изменить оригинальный \n",
    "        X_copy.insert(0, 'base', 1)                           # добавляем столбик для свободного члена, заполним его 1\n",
    "        X_copy = X_copy.to_numpy()  \n",
    "        self.__weights = np.ones(X_copy.shape[1])               # создаем вектор весов, заполненный 1\n",
    "\n",
    "        # Цикл обучения\n",
    "        for i in range(self.n_iter):\n",
    "            pred = X_copy.dot(self.__weights)                    # делаем предсказание модели\n",
    "            proba = 1 / (1 + np.exp(-pred))                    # переводим предсказания в вероятности через функцию сигмоиды\n",
    "            grad = (1/len(y))*(proba - y).dot(X_copy)          # вычисляем градиент LogLoss\n",
    "            #self.__weights -= self.learning_rate * grad          # делаем шаг обучения\n",
    "\n",
    "            if self.metric:                                    # если задана метрика \n",
    "                if i == self.n_iter-1:                         # считаем его на n - 1 итерации, чтобы последнне значение записать в best_score\n",
    "                    marks = (proba>0.5).astype(int)\n",
    "                    self.__best_score = self.__calculat_metric(y_true=y, y_pred=marks if self.metric!='roc_auc' else proba)\n",
    "\n",
    "            if verbose and (i % 10 == 0 or i == self.n_iter-1):\n",
    "                self.__log_training_step(i, X_copy, y, proba)\n",
    "\n",
    "            self.__weights -= self.learning_rate * grad          # делаем шаг обучения\n",
    "    def predict_proba(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет вероятностное предсказание модели\"\"\"\n",
    "        X_copy = X.copy()\n",
    "        X_copy.insert(0, 'base', 1)\n",
    "        pred = X_copy.dot(self.__weights)\n",
    "        proba = 1 / (1 + np.exp(-pred))\n",
    "        return np.array(proba)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет маркерное предсказание модели\"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.array((proba > 0.5).astype(int))\n",
    "\n",
    "    def get_best_score(self):\n",
    "        if self.metric is None:\n",
    "            raise ValueError(\"Metric was not set during model initialization.\")\n",
    "        return self.__best_score\n",
    "                \n",
    "    def get_coef(self) -> np.array:\n",
    "        return np.array(self.__weights[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc33a79-428a-4b3d-97d4-cb4e34a56bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
