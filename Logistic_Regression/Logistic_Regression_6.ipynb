{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4820f4-1b5f-4fb5-a5aa-f08f73174f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc4b0fcf-8f5e-44e8-8624-cd40a70623e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=400, n_features=4)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bae2c7-f381-4263-ae1c-9f7924a02a17",
   "metadata": {},
   "source": [
    "#### Добавим динамический шаг обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c89420-4e2a-4af4-b3c8-595e29ebcce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a516551f-2ec2-4e37-ba19-9a4d31e6257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_learning_rate(iteration):\n",
    "        \"\"\"Динамический или статический lr.\"\"\"\n",
    "        if callable(learning_rate):\n",
    "            return learning_rate(iteration)\n",
    "        else:\n",
    "            return self.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e2b20-5311-4328-9c1f-e4d273a35a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f54941-47c5-4e71-b8fd-2b8f1ef47bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c8b651-8c64-43b1-8cd2-aea11659019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg():\n",
    "    def __init__(self, n_iter=10, learning_rate=0.1, reg=None, l1_coef=0, l2_coef=0, metric=None, weights=None):\n",
    "        self.n_iter = n_iter \n",
    "        self.learning_rate = learning_rate\n",
    "        self.__weights = weights\n",
    "        self.metric = metric\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.__best_score = None\n",
    "\n",
    "        self.__validate_params()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "\n",
    "    def __validate_params(self):\n",
    "        \"\"\"Проверяет корректность параметров модели.\"\"\"\n",
    "        if self.metric is not None and self.metric not in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            raise ValueError(f\"Invalid metric: {self.metric}, You can only use: 'accuracy', 'precision', 'recall', 'f1' or 'roc_auc' \")\n",
    "        # Проверям на входные параметры регулиризации \n",
    "        if self.reg is not None and self.reg not in ['l1', 'l2', 'elasticnet']:\n",
    "            raise ValueError(\"reg must be 'l1', 'l2', or 'elasticnet'\")\n",
    "        # Проверка коэффициентов (должны быть от 0 до 1)\n",
    "        if self.l1_coef < 0 or self.l1_coef > 1:\n",
    "            raise ValueError(\"l1_coef must be in [0, 1]\")\n",
    "        if self.l2_coef < 0 or self.l2_coef > 1:\n",
    "            raise ValueError(\"l2_coef must be in [0, 1]\")\n",
    "    \n",
    "    def __log_training_step(self, iteration: int, y: np.array, proba: np.array, w: np.array):\n",
    "        \"\"\"Логирует процесс обучения (итерацию, веса, функцию потерь).\n",
    "    \n",
    "        Параметры:\n",
    "        iteration: int - номер итерации\n",
    "        X: np.array - матрица признаков\n",
    "        y: np.array - вектор истинных меток (0 или 1)\n",
    "        proba: np.array - предсказанные вероятности класса 1\n",
    "        \"\"\"\n",
    "        loss = self.__calculate_loss(y, proba, w)                           # считаем loss \n",
    "        metric_value = None                                                 # Инициализируем метрикику \n",
    "        if self.metric:                                                     # если она задана \n",
    "            y_pred = (proba>0.5).astype(int)                                # вероятности переводим в метки\n",
    "            metric_value = self.__calculat_metric(y, y_pred if self.metric != 'roc_auc' else proba)       # cчитаем метрику\n",
    "            \n",
    "        if iteration == 0:\n",
    "            if self.metric:\n",
    "                print(f'start | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'start | loss: {loss:0.2f}')\n",
    "        else:\n",
    "            if self.metric:\n",
    "                print(f'{iteration} | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'{iteration} | loss: {loss:0.2f}')\n",
    "    def __calculate_loss(self, y: np.array, proba: np.array, w: np.array) -> float:\n",
    "        \"\"\"\n",
    "        Вычисляем общий loss (MSLE + регуляризация).\n",
    "        X: np.array (Матрица признаков)\n",
    "        y: np.array (Вектор значений)\n",
    "        w: np.array (Вектор весов)\n",
    "        \"\"\"\n",
    "        eps = 1e-15\n",
    "        loss = -np.mean(y*np.log(proba+eps) + (1-y)*(np.log(1-proba+eps)))\n",
    "\n",
    "        if self.reg == 'l1':\n",
    "            return loss + self.l1_coef * np.sum(np.abs(w))\n",
    "        elif self.reg == 'l2':\n",
    "            return loss + self.l2_coef * np.sum(w**2)\n",
    "        elif self.reg == 'elasticnet':\n",
    "            return loss + self.l1_coef * np.sum(np.abs(w)) + self.l2_coef * np.sum(w**2)\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "    def __apply_regularization(self, grad: np.array, w: np.array):\n",
    "        \"\"\"Добавляет градиент регуляризации.\"\"\"\n",
    "        if self.reg == 'l1':\n",
    "            return grad + self.l1_coef * np.sign(w)\n",
    "        elif self.reg == 'l2':\n",
    "            return grad + 2 * self.l2_coef * w\n",
    "        elif self.reg == 'elasticnet':\n",
    "            return grad + self.l1_coef * np.sign(w) + 2 * self.l2_coef * w\n",
    "        else:\n",
    "            return grad\n",
    "    \n",
    "    def __calculat_metric(self, y_true: np.array, y_pred: np.array):\n",
    "        \"\"\"Считает заданные метрики.\"\"\"\n",
    "        #  Напишем функцию для подсчета матрицы ошибок\n",
    "        def confusion_matrix(y_true: np.array, y_pred: np.array):\n",
    "            # инициализируем нашу матрицу ошибок\n",
    "            tn = fn = fp = tp = 0 \n",
    "            for true, pred in zip(y_true, y_pred):\n",
    "                if pred == 0 and true == 0:          # TN\n",
    "                    tn += 1 \n",
    "                elif pred == 0 and true == 1:        # FN\n",
    "                    fn += 1 \n",
    "                elif pred == 1 and true == 0:        # FP\n",
    "                    fp += 1 \n",
    "                elif pred == 1 and true == 1:        # TP\n",
    "                    tp += 1 \n",
    "            return tn, fn, fp, tp\n",
    "        \n",
    "        if self.metric == 'roc_auc':\n",
    "            # Предсказанные вероятности\n",
    "            y_scores = y_pred\n",
    "            # Сортируем по вероятностям\n",
    "            sorted_indices = np.argsort(y_scores)\n",
    "            sorted_y = np.array(y_true)[sorted_indices]\n",
    "\n",
    "            # Присваиваем ранги (от 1 до n, как в scipy)\n",
    "            n = len(y_scores)\n",
    "            ranks = np.empty(n)\n",
    "            i = 0\n",
    "            while i < n:\n",
    "                j = i\n",
    "                while j + 1 < n and y_scores[sorted_indices[j]] == y_scores[sorted_indices[j + 1]]:\n",
    "                    j += 1\n",
    "                avg_rank = (i + j + 2) / 2  # т.к. ранги начинаются с 1\n",
    "                for k in range(i, j + 1):\n",
    "                    ranks[k] = avg_rank\n",
    "                i = j + 1\n",
    "\n",
    "            # Считаем сумму рангов положительного класса\n",
    "            sum_ranks_pos = np.sum(ranks[sorted_y == 1])\n",
    "\n",
    "            P = np.sum(sorted_y)         # количество положительных\n",
    "            N = n - P                    # количество отрицательных\n",
    "\n",
    "            if P == 0 or N == 0:\n",
    "                return None\n",
    "            # Вычисляем AUC по формуле Манна-Уитни\n",
    "            auc = (sum_ranks_pos - P * (P + 1) / 2) / (P * N)\n",
    "            return auc\n",
    "        tn, fn, fp, tp = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        if self.metric == 'accuracy':\n",
    "            return (tp + tn) / (tp + tn + fp + fn)\n",
    "        elif self.metric == 'precision':\n",
    "            return tp / (tp + fp)\n",
    "        elif self.metric == 'recall':\n",
    "            return tp / (tp + fn)\n",
    "        elif self.metric == 'f1':\n",
    "            pr = tp / (tp + fp)      # precision\n",
    "            re = tp / (tp + fn)      # recall\n",
    "            return (2*pr*re) / (pr + re)\n",
    "\n",
    "    def __get_learning_rate(self, iteration: int):\n",
    "        \"\"\"Динамический или статический lr.\"\"\"\n",
    "        if callable(self.learning_rate):\n",
    "            return self.learning_rate(iteration)\n",
    "        else:\n",
    "            return self.learning_rate\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose=False):\n",
    "        \"\"\"\n",
    "        Метод обучает модель Логистической регресси \n",
    "        Входные параметры:\n",
    "        X: pd.DataFrame\n",
    "        y: pd.Series\n",
    "        verbose: bool\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()                                       # копируем матрицу признаков, чтобы не изменить оригинальный \n",
    "        X_copy.insert(0, 'base', 1)                             # добавляем столбик для свободного члена, заполним его 1\n",
    "        X_copy = X_copy.to_numpy()  \n",
    "        self.__weights = np.ones(X_copy.shape[1])               # создаем вектор весов, заполненный 1\n",
    "\n",
    "        # Цикл обучения\n",
    "        for i in range(self.n_iter):\n",
    "            pred = X_copy.dot(self.__weights)                   # делаем предсказание модели\n",
    "            proba = 1 / (1 + np.exp(-pred))                     # переводим предсказания в вероятности через функцию сигмоиды\n",
    "            grad = (1/len(y))*(proba - y).dot(X_copy)           # вычисляем градиент LogLoss\n",
    "            grad = self.__apply_regularization(grad, self.__weights)   # добавляем регуляризацию\n",
    "            #self.__weights -= self.learning_rate * grad        # делаем шаг обучения\n",
    "            if self.metric:                                    # если задана метрика \n",
    "                if i == self.n_iter-1:                         # считаем его на n - 1 итерации, чтобы последнне значение записать в best_score\n",
    "                    marks = (proba>0.5).astype(int)\n",
    "                    self.__best_score = self.__calculat_metric(y_true=y, y_pred=marks if self.metric!='roc_auc' else proba)\n",
    "\n",
    "            if verbose and (i % 10 == 0 or i == self.n_iter-1):\n",
    "                self.__log_training_step(i, y, proba, self.__weights)\n",
    "\n",
    "            lr = self.__get_learning_rate(i+1)   # проверяем на динамичность шаг обучения\n",
    "            self.__weights -= lr * grad          # делаем шаг обучения\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет вероятностное предсказание модели\"\"\"\n",
    "        X_copy = X.copy()\n",
    "        X_copy.insert(0, 'base', 1)\n",
    "        pred = X_copy.dot(self.__weights)\n",
    "        proba = 1 / (1 + np.exp(-pred))\n",
    "        return np.array(proba)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет маркерное предсказание модели\"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.array((proba > 0.5).astype(int))\n",
    "\n",
    "    def get_best_score(self):\n",
    "        if self.metric is None:\n",
    "            raise ValueError(\"Metric was not set during model initialization.\")\n",
    "        return self.__best_score\n",
    "                \n",
    "    def get_coef(self) -> np.array:\n",
    "        return np.array(self.__weights[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32457b9f-d602-414d-b5d7-c2381e0ae55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49489f6a-b4bd-4682-be03-064ffc438ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b7245c-ec0d-407a-95c3-0aeb1c4d91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLogReg(learning_rate=lambda iter: 0.5 * (0.85 ** iter), n_iter=100, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0800f7c-e21f-4a38-b638-472ef421a9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22185265624999997"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = lambda iter: 0.5 * (0.85 ** iter)\n",
    "a(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce05a677-85ab-40b4-8933-b3f7e70060c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 0.61 | accuracy: 0.68\n",
      "10 | loss: 0.35 | accuracy: 0.94\n",
      "20 | loss: 0.33 | accuracy: 0.94\n",
      "30 | loss: 0.33 | accuracy: 0.94\n",
      "40 | loss: 0.33 | accuracy: 0.94\n",
      "50 | loss: 0.33 | accuracy: 0.94\n",
      "60 | loss: 0.33 | accuracy: 0.94\n",
      "70 | loss: 0.33 | accuracy: 0.94\n",
      "80 | loss: 0.33 | accuracy: 0.94\n",
      "90 | loss: 0.33 | accuracy: 0.94\n",
      "99 | loss: 0.33 | accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "904d7f95-0f75-4c20-9f62-854ecf12adca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.945"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09e883-2ebd-42d6-9284-8683274f50fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eee9a465-5db6-47a4-a02d-3825a71f74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 0.61 | accuracy: 0.68\n",
      "10 | loss: 0.44 | accuracy: 0.74\n",
      "20 | loss: 0.36 | accuracy: 0.93\n",
      "30 | loss: 0.33 | accuracy: 0.94\n",
      "40 | loss: 0.30 | accuracy: 0.94\n",
      "50 | loss: 0.29 | accuracy: 0.94\n",
      "60 | loss: 0.28 | accuracy: 0.94\n",
      "70 | loss: 0.27 | accuracy: 0.93\n",
      "80 | loss: 0.26 | accuracy: 0.93\n",
      "90 | loss: 0.26 | accuracy: 0.93\n",
      "99 | loss: 0.26 | accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "model1 = MyLogReg(n_iter=100, metric='accuracy')\n",
    "model1.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "06983dec-50e0-4467-89d3-11cbd8dfa102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e21d5a3-e75f-4e74-a6d4-1f15fc60fa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLogReg class: n_iter=100, learning_rate=0.1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bc0fb9d-dd63-413a-a24a-26c3ab081698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9665899-6f4d-42b1-9275-98174dd9779f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05651799, 0.76481181, 2.29318365, 0.49405837])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64f819-a2bb-45de-91af-ba963761293a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
