{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4135bcfa-1dad-4a28-9c4d-74363d33b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7ae4cf-d9d1-4c23-b373-ac84495b007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=400, n_features=4)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb12ee73-5404-42b8-92f7-cd2f6a6efb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "395    0\n",
       "396    1\n",
       "397    1\n",
       "398    0\n",
       "399    1\n",
       "Length: 400, dtype: int32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "615cd748-2913-46b8-995d-8150dd5d5c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ручной ROC AUC: 0.60714\n"
     ]
    }
   ],
   "source": [
    "def manual_roc_auc(y_true, y_scores):\n",
    "    # 1. Разделим все объекты на положительные (label == 1) и отрицательные (label == 0)\n",
    "    positives = [(score, label) for score, label in zip(y_scores, y_true) if label == 1]\n",
    "    negatives = [(score, label) for score, label in zip(y_scores, y_true) if label == 0]\n",
    "\n",
    "    P = len(positives)  # Количество положительных примеров\n",
    "    N = len(negatives)  # Количество отрицательных примеров\n",
    "\n",
    "    # 2. Проверка: если одного из классов нет, метрика не считается\n",
    "    if P == 0 or N == 0:\n",
    "        return None  # Нельзя вычислить AUC без положительных или отрицательных примеров\n",
    "\n",
    "    total = 0  # Накопитель для суммы сравнения скоров\n",
    "\n",
    "    # 3. Проходим по всем отрицательным примерам\n",
    "    for neg_score, _ in negatives:\n",
    "        # Считаем, сколько положительных примеров имеют больший скор\n",
    "        count_higher = sum(1 for pos_score, _ in positives if pos_score > neg_score)\n",
    "        # Считаем, сколько положительных примеров имеют такой же скор\n",
    "        count_equal = sum(1 for pos_score, _ in positives if pos_score == neg_score)\n",
    "        # Добавляем к сумме: полное количество выше + половину от равных\n",
    "        total += count_higher + 0.5 * count_equal\n",
    "\n",
    "    # 4. Нормализация суммы: делим на общее количество пар (P * N)\n",
    "    auc = total / (P * N)\n",
    "    return auc\n",
    "\n",
    "y_scores = [0.91, 0.86, 0.78, 0.6, 0.6, 0.55, 0.51, 0.46, 0.45, 0.45, 0.42]\n",
    "y_true =   [1,    0,    0,   1,   0,   1,   0,   0,   0,   1,   0]\n",
    "\n",
    "result = manual_roc_auc(y_true, y_scores)\n",
    "print(f\"Ручной ROC AUC: {result:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a370e5c-7ed2-4fb3-8e2a-1c50c49a6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogReg():\n",
    "    def __init__(self, n_iter=10, learning_rate=0.1, metric=None, weights=None):\n",
    "        self.n_iter = n_iter \n",
    "        self.learning_rate = learning_rate\n",
    "        self.__weights = weights\n",
    "        self.metric = metric\n",
    "        self.__best_score = None\n",
    "\n",
    "        self.__validate_params()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'MyLogReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "\n",
    "    def __validate_params(self):\n",
    "        \"\"\"Проверяет корректность параметров модели.\"\"\"\n",
    "        if self.metric is not None and self.metric not in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']:\n",
    "            raise ValueError(f\"Invalid metric: {self.metric}, You can only use: 'accuracy', 'precision', 'recall', 'f1' or 'roc_auc' \")\n",
    "    \n",
    "    def __log_training_step(self, iteration: int, X: np.array, y: np.array, proba: np.array):\n",
    "        \"\"\"Логирует процесс обучения (итерацию, веса, функцию потерь).\n",
    "    \n",
    "        Параметры:\n",
    "        iteration: int - номер итерации\n",
    "        X: np.array - матрица признаков\n",
    "        y: np.array - вектор истинных меток (0 или 1)\n",
    "        proba: np.array - предсказанные вероятности класса 1\n",
    "        \"\"\"\n",
    "        eps = 1e-15\n",
    "        loss = -np.mean(y*np.log(proba+eps) + (1-y)*(np.log(1-proba+eps)))\n",
    "        \n",
    "        metric_value = None                                                 # Инициализируем метрикику \n",
    "        if self.metric:                                                     # если она задана \n",
    "            y_pred = (proba>0.5).astype(int)                                # вероятности переводим в метки\n",
    "            metric_value = self.__calculat_metric(y, y_pred if self.metric != 'roc_auc' else proba)       # cчитаем метрику\n",
    "            \n",
    "        if iteration == 0:\n",
    "            if self.metric:\n",
    "                print(f'start | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'start | loss: {loss:0.2f}')\n",
    "        else:\n",
    "            if self.metric:\n",
    "                print(f'{iteration} | loss: {loss:0.2f} | {self.metric}: {metric_value:0.2f}')\n",
    "            else:\n",
    "                print(f'{iteration} | loss: {loss:0.2f}')\n",
    "\n",
    "    def __calculat_metric(self, y_true: np.array, y_pred: np.array):\n",
    "        \"\"\"\n",
    "        Считает заданные метрики\n",
    "        \"\"\"\n",
    "        #  Напишем функцию для подсчета матрицы ошибок\n",
    "        def confusion_matrix(y_true: np.array, y_pred: np.array):\n",
    "            # инициализируем нашу матрицу ошибок\n",
    "            tn = fn = fp = tp = 0 \n",
    "            for true, pred in zip(y_true, y_pred):\n",
    "                if pred == 0 and true == 0:          # TN\n",
    "                    tn += 1 \n",
    "                elif pred == 0 and true == 1:        # FN\n",
    "                    fn += 1 \n",
    "                elif pred == 1 and true == 0:        # FP\n",
    "                    fp += 1 \n",
    "                elif pred == 1 and true == 1:        # TP\n",
    "                    tp += 1 \n",
    "            return tn, fn, fp, tp\n",
    "\n",
    "        if self.metric == 'roc_auc':\n",
    "            # Предсказанные вероятности\n",
    "            y_scores = y_pred\n",
    "            # Сортируем по вероятностям\n",
    "            sorted_indices = np.argsort(y_scores)\n",
    "            sorted_y = np.array(y_true)[sorted_indices]\n",
    "\n",
    "            # Присваиваем ранги (от 1 до n, как в scipy)\n",
    "            n = len(y_scores)\n",
    "            ranks = np.empty(n)\n",
    "            i = 0\n",
    "            while i < n:\n",
    "                j = i\n",
    "                while j + 1 < n and y_scores[sorted_indices[j]] == y_scores[sorted_indices[j + 1]]:\n",
    "                    j += 1\n",
    "                avg_rank = (i + j + 2) / 2  # т.к. ранги начинаются с 1\n",
    "                for k in range(i, j + 1):\n",
    "                    ranks[k] = avg_rank\n",
    "                i = j + 1\n",
    "\n",
    "            # Считаем сумму рангов положительного класса\n",
    "            sum_ranks_pos = np.sum(ranks[sorted_y == 1])\n",
    "\n",
    "            P = np.sum(sorted_y)         # количество положительных\n",
    "            N = n - P                    # количество отрицательных\n",
    "\n",
    "            if P == 0 or N == 0:\n",
    "                return None\n",
    "            # Вычисляем AUC по формуле Манна-Уитни\n",
    "            auc = (sum_ranks_pos - P * (P + 1) / 2) / (P * N)\n",
    "            return auc\n",
    "\n",
    "        tn, fn, fp, tp = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        if self.metric == 'accuracy':\n",
    "            return (tp + tn) / (tp + tn + fp + fn)\n",
    "        elif self.metric == 'precision':\n",
    "            return tp / (tp + fp)\n",
    "        elif self.metric == 'recall':\n",
    "            return tp / (tp + fn)\n",
    "        elif self.metric == 'f1':\n",
    "            pr = tp / (tp + fp)      # precision\n",
    "            re = tp / (tp + fn)      # recall\n",
    "            return (2*pr*re) / (pr + re)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose=False):\n",
    "        \"\"\"\n",
    "        Метод обучает модель Логистической регресси \n",
    "        Входные параметры:\n",
    "        X: pd.DataFrame\n",
    "        y: pd.Series\n",
    "        verbose: bool\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()                                     # копируем матрицу признаков, чтобы не изменить оригинальный \n",
    "        X_copy.insert(0, 'base', 1)                           # добавляем столбик для свободного члена, заполним его 1\n",
    "        X_copy = X_copy.to_numpy()  \n",
    "        self.__weights = np.ones(X_copy.shape[1])               # создаем вектор весов, заполненный 1\n",
    "\n",
    "        # Цикл обучения\n",
    "        for i in range(self.n_iter):\n",
    "            pred = X_copy.dot(self.__weights)                    # делаем предсказание модели\n",
    "            proba = 1 / (1 + np.exp(-pred))                    # переводим предсказания в вероятности через функцию сигмоиды\n",
    "            grad = (1/len(y))*(proba - y).dot(X_copy)          # вычисляем градиент LogLoss\n",
    "            #self.__weights -= self.learning_rate * grad          # делаем шаг обучения\n",
    "\n",
    "            if self.metric:                                    # если задана метрика \n",
    "                if i == self.n_iter-1:                         # считаем его на n - 1 итерации, чтобы последнне значение записать в best_score\n",
    "                    marks = (proba>0.5).astype(int)\n",
    "                    self.__best_score = self.__calculat_metric(y_true=y, y_pred=marks if self.metric!='roc_auc' else proba)\n",
    "\n",
    "            if verbose and (i % 10 == 0 or i == self.n_iter-1):\n",
    "                self.__log_training_step(i, X_copy, y, proba)\n",
    "\n",
    "            self.__weights -= self.learning_rate * grad          # делаем шаг обучения\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет вероятностное предсказание модели\"\"\"\n",
    "        X_copy = X.copy()\n",
    "        X_copy.insert(0, 'base', 1)\n",
    "        pred = X_copy.dot(self.__weights)\n",
    "        proba = 1 / (1 + np.exp(-pred))\n",
    "        return np.array(proba)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"Вернет маркерное предсказание модели\"\"\"\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.array((proba > 0.5).astype(int))\n",
    "\n",
    "    def get_best_score(self):\n",
    "        if self.metric is None:\n",
    "            raise ValueError(\"Metric was not set during model initialization.\")\n",
    "        return self.__best_score\n",
    "                \n",
    "    def get_coef(self) -> np.array:\n",
    "        return np.array(self.__weights[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec5982e-c21d-4e24-b091-b14e216d3e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011e053-b4da-4d41-bb37-3d50859323c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af541b3c-5ea3-475a-ac11-a054d2d7d798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a1406e5-81e1-4aec-91b9-242bfbd6005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLogReg(n_iter=100, metric='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9aa46d75-e354-4cf4-a61a-a01bf794dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 0.74 | roc_auc: 0.68\n",
      "10 | loss: 0.49 | roc_auc: 0.91\n",
      "20 | loss: 0.40 | roc_auc: 0.96\n",
      "30 | loss: 0.35 | roc_auc: 0.97\n",
      "40 | loss: 0.33 | roc_auc: 0.97\n",
      "50 | loss: 0.31 | roc_auc: 0.97\n",
      "60 | loss: 0.29 | roc_auc: 0.97\n",
      "70 | loss: 0.28 | roc_auc: 0.97\n",
      "80 | loss: 0.28 | roc_auc: 0.97\n",
      "90 | loss: 0.27 | roc_auc: 0.97\n",
      "99 | loss: 0.26 | roc_auc: 0.97\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a4f604d-6f77-44eb-a23b-cef78edf1398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705242631065777"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_best_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b3692c34-b1f5-4654-a10e-b9281285b537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.15576987, 0.16753171, 1.23971409, 0.63866576])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_coef()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af9db8-0e1d-464b-ae19-66a9df4815f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40f8f541-44df-41b2-af8e-6279d365fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict_proba(X.iloc[:5]) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da3b7a3d-7167-4586-9885-b6fe5f0a5e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b3d69-b8a8-49e6-bbce-a28ff76e57e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323b86bf-8381-48c8-ac1a-8e5e2a62b11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c2296-c7f2-4674-947e-d5736450eab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
