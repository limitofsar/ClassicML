{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "67d7263c-16ec-48c5-ad57-cb4f0cbe9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0b0740ab-5720-48e4-ae6a-d34e3751c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples= 300, n_features=3, noise=15, random_state=42)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b02c02-cf1e-4f07-99a3-811dfaef55ef",
   "metadata": {},
   "source": [
    "#### Скорость обучения\n",
    "\n",
    "нужно добавить изменение шага обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f3314803-22f6-40c1-b7d7-0ea074a745fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg():\n",
    "    def __init__(self, n_iter=100, learning_rate=0.1, reg=None, l1_coef=0, l2_coef=0, metric=None, weights=None):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.metric = metric\n",
    "        self.weights = weights\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.best_score = None\n",
    "\n",
    "        # Проверям на входные параметры подсчета метрики\n",
    "        if self.metric is not None and self.metric not in ['mae', 'mse', 'rmse', 'mape', 'r2']:\n",
    "            raise ValueError(\"metric must be 'mae', 'mse', 'rmse', 'mape' or 'r2'\")\n",
    "        # Проверям на входные параметры регулиризации \n",
    "        if self.reg is not None and self.reg not in ['l1', 'l2', 'elasticnet']:\n",
    "            raise ValueError(\"reg must be 'l1', 'l2', or 'elasticnet'\")\n",
    "        # Проверка коэффициентов (должны быть от 0 до 1)\n",
    "        if self.l1_coef < 0 or self.l1_coef > 1:\n",
    "            raise ValueError(\"l1_coef must be in [0, 1]\")\n",
    "        if self.l2_coef < 0 or self.l2_coef > 1:\n",
    "            raise ValueError(\"l2_coef must be in [0, 1]\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "\n",
    "    # Напишем метод с приватным модификатором доступа для подсчета разнных метрик \n",
    "    def __calculate_metric(self, pred: pd.DataFrame, y_true: pd.Series, metric:'str'):\n",
    "        \"\"\"\n",
    "        Вычисляет значение метрики.\n",
    "\n",
    "        Параметры:\n",
    "        pred (np.array): Предсказанные значения.\n",
    "        y_true (np.array): Фактические значения.\n",
    "        metric (str): Название метрики.\n",
    "\n",
    "        Возвращает:\n",
    "        float: Значение метрики.\n",
    "        \"\"\"\n",
    "        if metric == 'mae':\n",
    "            return np.mean(np.abs(pred - y_true))\n",
    "        elif metric == 'mse':\n",
    "            return np.mean((pred - y_true)**2)\n",
    "        elif metric == 'rmse':\n",
    "            return np.sqrt(np.mean((pred - y_true)**2))\n",
    "        elif metric == 'mape':\n",
    "            return 100 * np.mean(np.abs((pred - y_true) / y_true))\n",
    "        elif metric == 'r2':\n",
    "            ss_residual = np.sum((pred - y_true)**2)\n",
    "            ss_total = np.sum((y_true - np.mean(y_true))**2)\n",
    "            return 1 - (ss_residual / ss_total)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {metric}\")\n",
    "    def fit(self, X: pd.DataFrame, y:pd.Series, verbose=False):\n",
    "        \"\"\"\n",
    "        Обучение модели линейной регрессии.\n",
    "\n",
    "        Параметры:\n",
    "        X (pd.DataFrame): Матрица признаков.\n",
    "        y (pd.Series): Вектор целевых значений.\n",
    "        verbose (bool): Флаг для вывода информации о процессе обучения.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()               # создадим копию нашей матрицы фичей, что бы не изменить изначальный\n",
    "        X_copy.insert(0, 'base', 1)     # допишем слева столбик из 1 для свободного члела\n",
    "        w = np.ones(X_copy.shape[1])    # составим вектор весов, заполненный из 1\n",
    "\n",
    "        # Напишем подсчет ошибки до начала обучения\n",
    "        if verbose:                   \n",
    "            initial_MSE = np.mean((np.dot(X_copy, w) - y)**2)          # ошибка MSE + L1 \n",
    "            if self.reg == 'l1':\n",
    "                initial_MSE += self.l1_coef * np.sum(np.abs(w))    # ошибка MSE + L2\n",
    "            if self.reg == 'l2':\n",
    "                initial_MSE += self.l2_coef * np.sum(w**2)         # ошибка MSE + elasticnet\n",
    "            if self.reg == 'elasticnet':\n",
    "                initial_MSE += self.l1_coef * np.sum(np.abs(w)) + self.l2_coef * np.sum(w**2)\n",
    "                \n",
    "            if self.metric is None:                          # Если не задана метрика, то в логи выводим только MSE\n",
    "                print(f'start | loss: {initial_MSE:0.2f}')   \n",
    "            else:                                            # Если задана, то выводим ошибку на MSE и на выбранной нами метрике\n",
    "                print(f'start | loss: {initial_MSE:0.2f} | {self.metric}: {self.__calculate_metric(pred=X_copy.dot(w), y_true=y, metric=self.metric):0.2f}')\n",
    "            \n",
    "        for i in range(self.n_iter): # Напишем цикл обучения\n",
    "            pred = np.dot(X_copy, w) # cчитаем предасказания модели \n",
    "            error = pred - y         # вычисляем ошибку (предсказания - реальные значения)\n",
    "            grad = (2/len(X_copy)) * np.dot(error, X_copy) # вычисляем градиенты по весам  (Градиент MSE)\n",
    "\n",
    "            # добавим градиент регуляризации к весам модели, если она установлена\n",
    "            if self.reg == 'l1':                                         # градиент MSE с L1 регуляризацией \n",
    "                grad += self.l1_coef * np.sign(w)\n",
    "            elif self.reg == 'l2':                                       # градиент MSE с L2 регуляризацией \n",
    "                grad += 2 * self.l2_coef * w \n",
    "            elif self.reg == 'elasticnet':                               # градиент MSE c elasticnet регуляризацией\n",
    "                grad += self.l1_coef * np.sign(w) + 2 * self.l2_coef * w\n",
    "                \n",
    "            if self.metric:         # Если задана метрика, то считаем его и обновляем self.best_score\n",
    "                metric_loss = self.__calculate_metric(pred = X_copy.dot(w), y_true=y, metric=self.metric) # Считаем выбранную метрику\n",
    "                self.best_score = metric_loss\n",
    "\n",
    "            if verbose:     # выводим логи \n",
    "                loss = np.mean(error**2)\n",
    "                if self.reg == 'l1':                             # Если L1 то к ошибке MSE + L1\n",
    "                    loss += self.l1_coef * np.sum(np.abs(w)) \n",
    "                if self.reg == 'l2':                            \n",
    "                    loss += self.l2_coef * np.sum((w)**2)   # Если L2 то к ошибке MSE + L2\n",
    "                if self.reg == 'elasticnet':                     # Есле elasticnet то к ошибке MSE + elasticnet\n",
    "                    loss += self.l1_coef * np.sum(np.abs(w)) + self.l2_coef * np.sum((w)**2)\n",
    "                if self.metric is None and i % 10 == 0:        # Eсли метрика не указана, то в логи выыодим итерацию и ошибку на MSE\n",
    "                    print(f'Iteration {i}| loss: {loss}')\n",
    "                elif self.metric and (i % 10 == 0 or self.n_iter - 1 == i): # Если указана метрика, то выводим ошибку MSE и на метрике\n",
    "                    print(f'Iteration {i}| loss: {loss:0.2f} | {self.metric}: {metric_loss:0.2f}')\n",
    "            if callable(self.learning_rate):        \n",
    "                w -= self.learning_rate(i+1) * grad  # обновляем веса, обновляем тут, чтобы ошибка считалась правильно     \n",
    "            else:\n",
    "                w -= self.learning_rate * grad\n",
    "        # сохроняем веса\n",
    "        self.weights = w \n",
    "    def predict(self, X: pd.DataFrame)->np.array:\n",
    "        \"\"\"\n",
    "        Предсказание целевых значений.\n",
    "\n",
    "        Параметры:\n",
    "        X (pd.DataFrame): Матрица признаков.\n",
    "\n",
    "        Возвращает:\n",
    "        np.array: Предсказанные значения.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()            # делаем копию матрицы фичей, чтобы не менять изначальный датафрейм\n",
    "        X_copy.insert(0, 'base', 1)  # допишем слева столбик из 1 для свободного члена\n",
    "        predict = X_copy.dot(self.weights) # делаем предсказания X_copy @ self.weights\n",
    "        return predict \n",
    "\n",
    "    def get_best_score(self):  # Метод для вывода лучшего качетва на выбранной метрике\n",
    "        if self.metric is None:\n",
    "            raise ValueError(\"Metric was not set during model initialization.\")\n",
    "        return self.best_score\n",
    "\n",
    "    def get_coef(self):\n",
    "        return self.weights[1:] # метод для вывода весов начиная с 1го заначения            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "39674cce-2172-43a4-90be-b04b33bd4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lambda iter: 0.5 * (0.85 ** iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ca8b8e5f-2679-49c2-91bf-67ae029a9921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49193972827026317"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cbbe6503-300c-4761-8391-36699d47aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = MyLineReg(n_iter=30,learning_rate=lr, metric='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ba57cb83-cb49-4641-a5f8-0a82e4c8c6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 13352.60 | mse: 13352.60\n",
      "Iteration 0| loss: 13352.60 | mse: 13352.60\n",
      "Iteration 10| loss: 203.40 | mse: 203.40\n",
      "Iteration 20| loss: 203.37 | mse: 203.37\n",
      "Iteration 29| loss: 203.37 | mse: 203.37\n"
     ]
    }
   ],
   "source": [
    "model_lr.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ec64a9dd-7133-42ff-a471-ddf8604fafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLineReg(metric='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "298be7e1-0f09-458d-9fc9-8cc9cfd6582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 13352.60 | mse: 13352.60\n",
      "Iteration 0| loss: 13352.60 | mse: 13352.60\n",
      "Iteration 10| loss: 371.01 | mse: 371.01\n",
      "Iteration 20| loss: 205.61 | mse: 205.61\n",
      "Iteration 30| loss: 203.40 | mse: 203.40\n",
      "Iteration 40| loss: 203.37 | mse: 203.37\n",
      "Iteration 50| loss: 203.37 | mse: 203.37\n",
      "Iteration 60| loss: 203.37 | mse: 203.37\n",
      "Iteration 70| loss: 203.37 | mse: 203.37\n",
      "Iteration 80| loss: 203.37 | mse: 203.37\n",
      "Iteration 90| loss: 203.37 | mse: 203.37\n",
      "Iteration 99| loss: 203.37 | mse: 203.37\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259afa7-d973-4e2d-a01c-3a687111096f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
