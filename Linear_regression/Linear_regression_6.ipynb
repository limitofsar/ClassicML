{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d7263c-16ec-48c5-ad57-cb4f0cbe9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b0740ab-5720-48e4-ae6a-d34e3751c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples= 300, n_features=3, noise=15, random_state=42)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b02c02-cf1e-4f07-99a3-811dfaef55ef",
   "metadata": {},
   "source": [
    "#### Скорость обучения\n",
    "\n",
    "нужно добавить изменение шага обучения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3314803-22f6-40c1-b7d7-0ea074a745fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class MyLineReg():\n",
    "    def __init__(self, n_iter=100, learning_rate=0.1, reg=None, l1_coef=0, l2_coef=0, metric=None, weights=None):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.metric = metric\n",
    "        self.weights = weights\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.best_score = None\n",
    "\n",
    "        # Проверям на входные параметры подсчета метрики\n",
    "        if self.metric is not None and self.metric not in ['mae', 'mse', 'rmse', 'mape', 'r2']:\n",
    "            raise ValueError(\"metric must be 'mae', 'mse', 'rmse', 'mape' or 'r2'\")\n",
    "        # Проверям на входные параметры регулиризации \n",
    "        if self.reg is not None and self.reg not in ['l1', 'l2', 'elasticnet']:\n",
    "            raise ValueError(\"reg must be 'l1', 'l2', or 'elasticnet'\")\n",
    "        # Проверка коэффициентов (должны быть от 0 до 1)\n",
    "        if self.l1_coef < 0 or self.l1_coef > 1:\n",
    "            raise ValueError(\"l1_coef must be in [0, 1]\")\n",
    "        if self.l2_coef < 0 or self.l2_coef > 1:\n",
    "            raise ValueError(\"l2_coef must be in [0, 1]\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "\n",
    "    # Напишем метод с приватным модификатором доступа для подсчета разнных метрик \n",
    "    def __calculate_metric(self, pred: pd.DataFrame, y_true: pd.Series, metric:'str'):\n",
    "        \"\"\"\n",
    "        Вычисляет значение метрики.\n",
    "\n",
    "        Параметры:\n",
    "        pred (np.array): Предсказанные значения.\n",
    "        y_true (np.array): Фактические значения.\n",
    "        metric (str): Название метрики.\n",
    "\n",
    "        Возвращает:\n",
    "        float: Значение метрики.\n",
    "        \"\"\"\n",
    "        if metric == 'mae':\n",
    "            return np.mean(np.abs(pred - y_true))\n",
    "        elif metric == 'mse':\n",
    "            return np.mean((pred - y_true)**2)\n",
    "        elif metric == 'rmse':\n",
    "            return np.sqrt(np.mean((pred - y_true)**2))\n",
    "        elif metric == 'mape':\n",
    "            return 100 * np.mean(np.abs((pred - y_true) / y_true))\n",
    "        elif metric == 'r2':\n",
    "            ss_residual = np.sum((pred - y_true)**2)\n",
    "            ss_total = np.sum((y_true - np.mean(y_true))**2)\n",
    "            return 1 - (ss_residual / ss_total)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {metric}\")\n",
    "    def fit(self, X: pd.DataFrame, y:pd.Series, verbose=False):\n",
    "        \"\"\"\n",
    "        Обучение модели линейной регрессии.\n",
    "\n",
    "        Параметры:\n",
    "        X (pd.DataFrame): Матрица признаков.\n",
    "        y (pd.Series): Вектор целевых значений.\n",
    "        verbose (bool): Флаг для вывода информации о процессе обучения.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()               # создадим копию нашей матрицы фичей, что бы не изменить изначальный\n",
    "        X_copy.insert(0, 'base', 1)     # допишем слева столбик из 1 для свободного члела\n",
    "        w = np.ones(X_copy.shape[1])    # составим вектор весов, заполненный из 1\n",
    "\n",
    "        # Напишем подсчет ошибки до начала обучения\n",
    "        if verbose:                   \n",
    "            initial_MSE = np.mean((np.dot(X_copy, w) - y)**2)          # ошибка MSE + L1 \n",
    "            if self.reg == 'l1':\n",
    "                initial_MSE += self.l1_coef * np.sum(np.abs(w))    # ошибка MSE + L2\n",
    "            if self.reg == 'l2':\n",
    "                initial_MSE += self.l2_coef * np.sum(w**2)         # ошибка MSE + elasticnet\n",
    "            if self.reg == 'elasticnet':\n",
    "                initial_MSE += self.l1_coef * np.sum(np.abs(w)) + self.l2_coef * np.sum(w**2)\n",
    "                \n",
    "            if self.metric is None:                          # Если не задана метрика, то в логи выводим только MSE\n",
    "                print(f'start | loss: {initial_MSE:0.2f}')   \n",
    "            else:                                            # Если задана, то выводим ошибку на MSE и на выбранной нами метрике\n",
    "                print(f'start | loss: {initial_MSE:0.2f} | {self.metric}: {self.__calculate_metric(pred=X_copy.dot(w), y_true=y, metric=self.metric):0.2f}')\n",
    "            \n",
    "        for i in range(self.n_iter): # Напишем цикл обучения\n",
    "            pred = np.dot(X_copy, w) # cчитаем предасказания модели \n",
    "            error = pred - y         # вычисляем ошибку (предсказания - реальные значения)\n",
    "            grad = (2/len(X_copy)) * np.dot(error, X_copy) # вычисляем градиенты по весам  (Градиент MSE)\n",
    "\n",
    "            # добавим градиент регуляризации к весам модели, если она установлена\n",
    "            if self.reg == 'l1':                                         # градиент MSE с L1 регуляризацией \n",
    "                grad += self.l1_coef * np.sign(w)\n",
    "            elif self.reg == 'l2':                                       # градиент MSE с L2 регуляризацией \n",
    "                grad += 2 * self.l2_coef * w \n",
    "            elif self.reg == 'elasticnet':                               # градиент MSE c elasticnet регуляризацией\n",
    "                grad += self.l1_coef * np.sign(w) + 2 * self.l2_coef * w\n",
    "                \n",
    "            if self.metric:         # Если задана метрика, то считаем его и обновляем self.best_score\n",
    "                metric_loss = self.__calculate_metric(pred = X_copy.dot(w), y_true=y, metric=self.metric) # Считаем выбранную метрику\n",
    "                self.best_score = metric_loss\n",
    "\n",
    "            if verbose:     # выводим логи \n",
    "                loss = np.mean(error**2)\n",
    "                if self.reg == 'l1':                             # Если L1 то к ошибке MSE + L1\n",
    "                    loss += self.l1_coef * np.sum(np.abs(w)) \n",
    "                if self.reg == 'l2':                            \n",
    "                    loss += self.l2_coef * np.sum((w)**2)   # Если L2 то к ошибке MSE + L2\n",
    "                if self.reg == 'elasticnet':                     # Есле elasticnet то к ошибке MSE + elasticnet\n",
    "                    loss += self.l1_coef * np.sum(np.abs(w)) + self.l2_coef * np.sum((w)**2)\n",
    "                if self.metric is None and i % 10 == 0:        # Eсли метрика не указана, то в логи выыодим итерацию и ошибку на MSE\n",
    "                    print(f'Iteration {i}| loss: {loss}')\n",
    "                elif self.metric and (i % 10 == 0 or self.n_iter - 1 == i): # Если указана метрика, то выводим ошибку MSE и на метрике\n",
    "                    print(f'Iteration {i}| loss: {loss:0.2f} | {self.metric}: {metric_loss:0.2f}')\n",
    "            if callable(self.learning_rate):        \n",
    "                w -= self.learning_rate(i+1) * grad  # обновляем веса, обновляем тут, чтобы ошибка считалась правильно     \n",
    "            else:\n",
    "                w -= self.learning_rate * grad\n",
    "        # сохроняем веса\n",
    "        self.weights = w \n",
    "    def predict(self, X: pd.DataFrame)->np.array:\n",
    "        \"\"\"\n",
    "        Предсказание целевых значений.\n",
    "\n",
    "        Параметры:\n",
    "        X (pd.DataFrame): Матрица признаков.\n",
    "\n",
    "        Возвращает:\n",
    "        np.array: Предсказанные значения.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()            # делаем копию матрицы фичей, чтобы не менять изначальный датафрейм\n",
    "        X_copy.insert(0, 'base', 1)  # допишем слева столбик из 1 для свободного члена\n",
    "        predict = X_copy.dot(self.weights) # делаем предсказания X_copy @ self.weights\n",
    "        return predict \n",
    "\n",
    "    def get_best_score(self):  # Метод для вывода лучшего качетва на выбранной метрике\n",
    "        if self.metric is None:\n",
    "            raise ValueError(\"Metric was not set during model initialization.\")\n",
    "        return self.best_score\n",
    "\n",
    "    def get_coef(self):\n",
    "        return self.weights[1:] # метод для вывода весов начиная с 1го заначения            \n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53442393-3016-406d-bbd7-08c642920332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61522184-7e4b-4844-80b3-7083baa453ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f846b6-a0e4-49f4-b193-8f92f1ff589b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1190590-5f94-4a3d-9aa2-b98073bf8910",
   "metadata": {},
   "source": [
    "Измененная улучшенная версия модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49b0051f-52c6-4db0-acf5-c9fd35ebb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg():\n",
    "    def __init__(self, n_iter=100, learning_rate=0.1, reg=None, l1_coef=0, l2_coef=0, metric=None, weights=None):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.metric = metric\n",
    "        self.weights = weights\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.best_score = None\n",
    "\n",
    "        self.__validate_params() # проверка входных параметров\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
    "        \n",
    "    def __validate_params(self):  # Проверяем на корректность входные параметры \n",
    "        # Проверям на входные параметры подсчета метрики\n",
    "        if self.metric is not None and self.metric not in ['mae', 'mse', 'rmse', 'mape', 'r2']:\n",
    "            raise ValueError(\"metric must be 'mae', 'mse', 'rmse', 'mape' or 'r2'\")\n",
    "        # Проверям на входные параметры регулиризации \n",
    "        if self.reg is not None and self.reg not in ['l1', 'l2', 'elasticnet']:\n",
    "            raise ValueError(\"reg must be 'l1', 'l2', or 'elasticnet'\")\n",
    "        # Проверка коэффициентов (должны быть от 0 до 1)\n",
    "        if self.l1_coef < 0 or self.l1_coef > 1:\n",
    "            raise ValueError(\"l1_coef must be in [0, 1]\")\n",
    "        if self.l2_coef < 0 or self.l2_coef > 1:\n",
    "            raise ValueError(\"l2_coef must be in [0, 1]\")\n",
    "\n",
    "    # Напишем метод с приватным модификатором доступа для подсчета разнных метрик \n",
    "    def __calculate_metric(self, pred: np.array, y_true: np.array, metric: str) -> float:\n",
    "        \"\"\"\n",
    "        Вычисляет значение метрики.\n",
    "\n",
    "        Параметры:\n",
    "        pred (np.array): Предсказанные значения.\n",
    "        y_true (np.array): Фактические значения.\n",
    "        metric (str): Название метрики.\n",
    "\n",
    "        Возвращает:\n",
    "        float: Значение метрики.\n",
    "        \"\"\"\n",
    "        if metric == 'mae':\n",
    "            return np.mean(np.abs(pred - y_true))\n",
    "        elif metric == 'mse':\n",
    "            return np.mean((pred - y_true)**2)\n",
    "        elif metric == 'rmse':\n",
    "            return np.sqrt(np.mean((pred - y_true)**2))\n",
    "        elif metric == 'mape':\n",
    "            return 100 * np.mean(np.abs((pred - y_true) / y_true))\n",
    "        elif metric == 'r2':\n",
    "            ss_residual = np.sum((pred - y_true)**2)\n",
    "            ss_total = np.sum((y_true - np.mean(y_true))**2)\n",
    "            return 1 - (ss_residual / ss_total)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {metric}\")\n",
    "            \n",
    "    def __calculate_loss(self, X: np.array, y: np.array, w: np.array) -> float:       \n",
    "        '''\n",
    "        Вычисляем общий loss (MSE + регуляризация).\n",
    "        X: np.array (Матрица признаков)\n",
    "        y: np.array (Вектор значений)\n",
    "        w: np.array (Вектор весов)\n",
    "        '''\n",
    "        error = np.dot(X,w) - y\n",
    "        MSE = np.mean(error**2) \n",
    "        \n",
    "        # Добавим регуляризацию, если она установлена\n",
    "        if self.reg == 'l1':\n",
    "            return MSE + self.l1_coef * np.sum(np.abs(w))\n",
    "        elif self.reg == 'l2':\n",
    "            return MSE + self.l2_coef * np.sum(w**2)\n",
    "        elif self.reg == 'elasticnet':\n",
    "            return MSE + self.l1_coef * np.sum(np.abs(w)) + self.l2_coef * np.sum(w**2)\n",
    "        else:\n",
    "            return MSE\n",
    "\n",
    "    def __log_training_step(self, iteration: int, X: np.array, y: np.array, w: np.array):\n",
    "        \"\"\"Логирует процесс обучения.\"\"\"\n",
    "        loss = self.__calculate_loss(X, y, w)\n",
    "        if self.metric:\n",
    "            metric_value = self.__calculate_metric(X.dot(w), y, self.metric)\n",
    "            print(f'Iteration {iteration} | loss: {loss:.2f} | {self.metric}: {metric_value:.2f}')\n",
    "        else:\n",
    "            print(f'Iteration {iteration} | loss: {loss:.2f}')\n",
    "\n",
    "    def __apply_regularization(self, grad: np.array, w: np.array) -> np.array:\n",
    "        \"\"\"Добавляет градиент регуляризации.\"\"\"\n",
    "        if self.reg == 'l1':\n",
    "            grad += self.l1_coef * np.sign(w)\n",
    "        elif self.reg == 'l2':\n",
    "            grad += 2 * self.l2_coef * w\n",
    "        elif self.reg == 'elasticnet':\n",
    "            grad += self.l1_coef * np.sign(w) + 2 * self.l2_coef * w\n",
    "        return grad\n",
    "\n",
    "    def __get_learning_rate(self, iteration: int) -> float:\n",
    "        \"\"\"Вычисляет learning_rate (статический или динамический).\"\"\"\n",
    "        if callable(self.learning_rate):\n",
    "            return self.learning_rate(iteration)\n",
    "        else:\n",
    "            return self.learning_rate\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y:pd.Series, verbose=False):\n",
    "        \"\"\"\n",
    "        Обучение модели линейной регрессии.\n",
    "\n",
    "        Параметры:\n",
    "        X (pd.DataFrame): Матрица признаков.\n",
    "        y (pd.Series): Вектор целевых значений.\n",
    "        verbose (bool): Флаг для вывода информации о процессе обучения.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()               # создадим копию нашей матрицы фичей, что бы не изменить изначальный\n",
    "        X_copy.insert(0, 'base', 1)     # допишем слева столбик из 1 для свободного члела\n",
    "        w = np.ones(X_copy.shape[1])    # составим вектор весов, заполненный из 1\n",
    "\n",
    "        if verbose:\n",
    "            loss = self.__calculate_loss(X_copy, y, w) # вычисляем loss\n",
    "            if self.metric is None:\n",
    "                print(f'start | loss: {loss:.2f}')\n",
    "            else:\n",
    "                metric = self.__calculate_metric(pred=X_copy.dot(w), y_true=y, metric=self.metric)\n",
    "                print(f'start | loss: {loss:0.2f} | {self.metric}: {metric:0.2f}')\n",
    "\n",
    "        # Напишем цикл обучения\n",
    "        for i in range(self.n_iter):\n",
    "            pred = X_copy.dot(w)                         # считаем предсказания модели\n",
    "            error = pred - y                             # вычислим ошибку (предсказания - реальные значения)\n",
    "            grad = (2/len(y)) * np.dot(error, X_copy)    # вычислим градиент по весам модели\n",
    "            grad = self.__apply_regularization(grad, w)  # добавим регуляризацию, если она задана\n",
    "\n",
    "            if self.metric:                              # Если задана метрика, то считаем её и обновляем self.best_score\n",
    "                self.best_score = self.__calculate_metric(pred=pred, y_true=y, metric=self.metric)\n",
    "            \n",
    "            if verbose and (i % 10 == 0 or i == self.n_iter - 1): # Eсли задано логирование, то выводим логи\n",
    "                self.__log_training_step(i, X_copy, y, w)\n",
    "\n",
    "            lr = self.__get_learning_rate(i+1)                    # проверяем на динамичность lr\n",
    "            w -= lr* grad                                         # делаем шаг обучения\n",
    "            \n",
    "        self.weights = w    # сохроняем веса\n",
    "\n",
    "    def predict(self, X: pd.DataFrame)->np.array:\n",
    "        \"\"\"\n",
    "        Предсказание целевых значений.\n",
    "\n",
    "        Параметры:\n",
    "        X (pd.DataFrame): Матрица признаков.\n",
    "\n",
    "        Возвращает:\n",
    "        np.array: Предсказанные значения.\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()            # делаем копию матрицы фичей, чтобы не менять изначальный датафрейм\n",
    "        X_copy.insert(0, 'base', 1)  # допишем слева столбик из 1 для свободного члена\n",
    "        predict = X_copy.dot(self.weights) # делаем предсказания X_copy @ self.weights\n",
    "        return predict \n",
    "\n",
    "    def get_best_score(self):  # Метод для вывода лучшего качетва на выбранной метрике\n",
    "        if self.metric is None:\n",
    "            raise ValueError(\"Metric was not set during model initialization.\")\n",
    "        return self.best_score\n",
    "\n",
    "    def get_coef(self):\n",
    "        return self.weights[1:] # метод для вывода весов начиная с 1го заначения            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5aca94-5379-4615-9c0a-99ff09bc49fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe211492-f883-4af4-8684-5612439f8fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39674cce-2172-43a4-90be-b04b33bd4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lambda iter: 0.5 * (0.85 ** iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca8b8e5f-2679-49c2-91bf-67ae029a9921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49193972827026317"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbbe6503-300c-4761-8391-36699d47aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = MyLineReg(n_iter=30,learning_rate=lr, metric='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba57cb83-cb49-4641-a5f8-0a82e4c8c6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 13352.60 | mse: 13352.60\n",
      "Iteration 0 | loss: 13352.60 | mse: 13352.60\n",
      "Iteration 10 | loss: 203.40 | mse: 203.40\n",
      "Iteration 20 | loss: 203.37 | mse: 203.37\n",
      "Iteration 29 | loss: 203.37 | mse: 203.37\n"
     ]
    }
   ],
   "source": [
    "model_lr.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec64a9dd-7133-42ff-a471-ddf8604fafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLineReg(n_iter=300,metric='mse', reg='elasticnet', l1_coef=0.9, l2_coef=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "298be7e1-0f09-458d-9fc9-8cc9cfd6582b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start | loss: 13356.20 | mse: 13352.60\n",
      "Iteration 0 | loss: 13356.20 | mse: 13352.60\n",
      "Iteration 10 | loss: 530.77 | mse: 388.16\n",
      "Iteration 20 | loss: 367.58 | mse: 208.65\n",
      "Iteration 30 | loss: 365.41 | mse: 204.52\n",
      "Iteration 40 | loss: 365.38 | mse: 204.25\n",
      "Iteration 50 | loss: 365.38 | mse: 204.22\n",
      "Iteration 60 | loss: 365.38 | mse: 204.21\n",
      "Iteration 70 | loss: 365.38 | mse: 204.21\n",
      "Iteration 80 | loss: 365.38 | mse: 204.21\n",
      "Iteration 90 | loss: 365.38 | mse: 204.21\n",
      "Iteration 100 | loss: 365.38 | mse: 204.21\n",
      "Iteration 110 | loss: 365.38 | mse: 204.21\n",
      "Iteration 120 | loss: 365.38 | mse: 204.21\n",
      "Iteration 130 | loss: 365.38 | mse: 204.21\n",
      "Iteration 140 | loss: 365.38 | mse: 204.21\n",
      "Iteration 150 | loss: 365.38 | mse: 204.21\n",
      "Iteration 160 | loss: 365.38 | mse: 204.21\n",
      "Iteration 170 | loss: 365.38 | mse: 204.21\n",
      "Iteration 180 | loss: 365.38 | mse: 204.21\n",
      "Iteration 190 | loss: 365.38 | mse: 204.21\n",
      "Iteration 200 | loss: 365.38 | mse: 204.21\n",
      "Iteration 210 | loss: 365.38 | mse: 204.21\n",
      "Iteration 220 | loss: 365.38 | mse: 204.21\n",
      "Iteration 230 | loss: 365.38 | mse: 204.21\n",
      "Iteration 240 | loss: 365.38 | mse: 204.21\n",
      "Iteration 250 | loss: 365.38 | mse: 204.21\n",
      "Iteration 260 | loss: 365.38 | mse: 204.21\n",
      "Iteration 270 | loss: 365.38 | mse: 204.21\n",
      "Iteration 280 | loss: 365.38 | mse: 204.21\n",
      "Iteration 290 | loss: 365.38 | mse: 204.21\n",
      "Iteration 299 | loss: 365.38 | mse: 204.21\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8259afa7-d973-4e2d-a01c-3a687111096f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.21476195, 81.08657754, 15.70601866])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249143f8-1977-453f-9a14-f3ac6f425f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e63908-087a-4a87-90c6-c90f5a1b72f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
