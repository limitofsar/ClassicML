{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "22061b94-985c-43ff-8bd9-6cd4cbfae2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1669ad55-4f64-4740-aaf3-c92e7c7f74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=400, n_features=4)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf955dec-c1eb-4304-a429-d4de3f855865",
   "metadata": {},
   "source": [
    "Пишем функцию для лучшего разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "144c0b4e-d26b-4cbc-86cf-4308e1f35225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y): \n",
    "    y = y.copy()\n",
    "    p = np.array([x/len(y) for x in np.bincount(y)])  # считаем вероятность вхождения каждого класса в сплит\n",
    "    p = p[p > 0]                                      # убираем 0 вероятности\n",
    "    return np.sum(-p*np.log2(p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "096786fe-8cb2-4341-9417-1af317235bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(y, y_left, y_right): \n",
    "    # Размеры выборок\n",
    "    n, n_left, n_right = len(y), len(y_left), len(y_right)\n",
    "    \n",
    "    # Если одна из подвыборок пуста — сплит бесполезен, прирост информации равен 0\n",
    "    if n_left == 0 or n_right == 0: \n",
    "        return 0\n",
    "    \n",
    "    # Энтропия исходной выборки (до разделения)\n",
    "    H_parent = entropy(y)\n",
    "    \n",
    "    # Энтропии левой и правой подвыборок (после разделения)\n",
    "    H_left = entropy(y_left)\n",
    "    H_right = entropy(y_right)\n",
    "    \n",
    "    # Прирост информации = уменьшение энтропии после разбиения\n",
    "    IG = H_parent - (n_left / n) * H_left - (n_right / n) * H_right\n",
    "    \n",
    "    # Возвращаем значение прироста информации\n",
    "    return IG\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "0c876503-9af2-415a-8bec-993a5935d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(X, y):\n",
    "    # Создаём копии X и y, чтобы не изменять исходные данные\n",
    "    X, y = X.copy(), y.copy()\n",
    "   \n",
    "    # Глобальные переменные для хранения лучшего сплита по всему датасету\n",
    "    best_IG = -np.inf           # Максимальный прирост информации среди всех колонок\n",
    "    best_col = None             # Название колонки, по которой достигается лучший сплит\n",
    "    best_split_value = None     # Значение сплита, которое даёт этот прирост\n",
    "        \n",
    "    # Проходим по каждой колонке признаков\n",
    "    for col in X.columns: \n",
    "        # Берём уникальные значения текущей колонки и сортируем их\n",
    "        unique_values = np.sort(X[col].unique())\n",
    "        \n",
    "        # Проходим по всем парам соседних уникальных значений для формирования порогов\n",
    "        for i in range(len(unique_values)-1): \n",
    "            # Порог для сплита — среднее между двумя соседними уникальными значениями\n",
    "            split = (unique_values[i] + unique_values[i+1]) / 2  \n",
    "            \n",
    "            # Создаём булевы маски для левой и правой подвыборки\n",
    "            left_mask = X[col] <= split\n",
    "            right_mask = X[col] > split\n",
    "            \n",
    "            # Формируем соответствующие подвыборки таргета\n",
    "            y_left, y_right = y[left_mask], y[right_mask]\n",
    "\n",
    "            # Вычисляем прирост информации для текущего сплита\n",
    "            IG = information_gain(y, y_left, y_right)\n",
    "            \n",
    "            # Если этот сплит даёт лучший прирост информации среди всех колонок — обновляем глобальные переменные\n",
    "            if IG > best_IG:\n",
    "                best_IG = IG\n",
    "                best_split_value = split\n",
    "                best_col = col\n",
    "    \n",
    "    # Возвращаем кортеж с лучшей колонкой, значением сплита и максимальным приростом информации\n",
    "    return best_col, best_split_value, best_IG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "043bcdc5-cad9-4b1f-8538-4bbeb0e8cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0,0,1,1])\n",
    "y_left = np.array([0,0])\n",
    "y_right = np.array([1,1])\n",
    "\n",
    "print(information_gain(y, y_left, y_right))  # должно быть ~1.0 (идеальное разделение)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9c0e0799-87cb-44cc-8aa8-7fdb38a9666f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y,minlength=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af0d3a-3265-4b25-99c6-b8ad27d3d86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "05ee4ebb-ca5c-42d7-9bc4-e538c2f817f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "4f979008-d105-4c66-833e-2122a35c1553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('f4', 0.2736670938170923, 0.564432013341756)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "c883985b-6448-4689-9505-9df39f170de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c71201b3-6af2-4dae-8395-33ba280bab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5cb4a4ac-ebc9-4d19-9230-6b2a84d97901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a515997-f048-44aa-ae02-6532a02ba9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ef585-5ef9-4afb-a5a7-873dc58bcbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa83f15-528e-425c-ad2a-7356e48fd2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "48488d8b-f54a-4b09-b051-18f6e5c87bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeClf:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20): \n",
    "        self.max_depth = max_depth \n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_leafs = max_leafs\n",
    "        \n",
    "    def __repr__(self): \n",
    "        return f'MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}'\n",
    "\n",
    "    def __entropy(self, y): \n",
    "        y = y.copy()\n",
    "        p = np.array([x/len(y) for x in np.bincount(y)])  # считаем вероятность вхождения каждого класса в сплит\n",
    "        p = p[p > 0]                                      # убираем 0 вероятности\n",
    "        return np.sum(-p*np.log2(p))\n",
    "\n",
    "    def __information_gain(self, y, y_left, y_right): \n",
    "        # Размеры выборок\n",
    "        n, n_left, n_right = len(y), len(y_left), len(y_right)\n",
    "        # Если одна из подвыборок пуста — сплит бесполезен, прирост информации равен 0\n",
    "        if n_left == 0 or n_right == 0: \n",
    "            return 0\n",
    "        # Энтропия исходной выборки (до разделения)\n",
    "        H_parent = self.__entropy(y)\n",
    "    \n",
    "        # Энтропии левой и правой подвыборок (после разделения)\n",
    "        H_left = self.__entropy(y_left)\n",
    "        H_right = self.__entropy(y_right)\n",
    "    \n",
    "        # Прирост информации = уменьшение энтропии после разбиения\n",
    "        IG = H_parent - (n_left / n) * H_left - (n_right / n) * H_right\n",
    "    \n",
    "        # Возвращаем значение прироста информации\n",
    "        return IG    \n",
    "\n",
    "    def __get_best_split(self, X, y):\n",
    "        # Создаём копии X и y, чтобы не изменять исходные данные\n",
    "        X, y = X.copy(), y.copy()\n",
    "   \n",
    "        # Глобальные переменные для хранения лучшего сплита по всему датасету\n",
    "        best_IG = -np.inf           # Максимальный прирост информации среди всех колонок\n",
    "        best_col = None             # Название колонки, по которой достигается лучший сплит\n",
    "        best_split_value = None     # Значение сплита, которое даёт этот прирост\n",
    "        \n",
    "        # Проходим по каждой колонке признаков\n",
    "        for col in X.columns: \n",
    "            # Берём уникальные значения текущей колонки и сортируем их\n",
    "            unique_values = np.sort(X[col].unique())\n",
    "        \n",
    "            # Проходим по всем парам соседних уникальных значений для формирования порогов\n",
    "            for i in range(len(unique_values)-1): \n",
    "                # Порог для сплита — среднее между двумя соседними уникальными значениями\n",
    "                split = (unique_values[i] + unique_values[i+1]) / 2  \n",
    "            \n",
    "                # Создаём булевы маски для левой и правой подвыборки\n",
    "                left_mask = X[col] <= split\n",
    "                right_mask = X[col] > split\n",
    "            \n",
    "                # Формируем соответствующие подвыборки таргета\n",
    "                y_left, y_right = y[left_mask], y[right_mask]\n",
    "\n",
    "                # Вычисляем прирост информации для текущего сплита\n",
    "                IG = self.__information_gain(y, y_left, y_right)\n",
    "            \n",
    "                # Если этот сплит даёт лучший прирост информации среди всех колонок — обновляем глобальные переменные\n",
    "                if IG > best_IG:\n",
    "                    best_IG = IG\n",
    "                    best_split_value = split\n",
    "                    best_col = col\n",
    "    \n",
    "        # Возвращаем кортеж с лучшей колонкой, значением сплита и максимальным приростом информации\n",
    "        return best_col, best_split_value, best_IG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "b4cb2ac9-33db-4b1f-b900-1dee1dd1e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MyTreeClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "f862e2cf-872b-4915-bfa1-ec1315b2899a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('f4', 0.2736670938170923, 0.564432013341756)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf9aa4-3a39-48d1-b384-4b74c0d26e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158029b7-ee1c-4ea7-bfb8-fd3e0e90ef25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
