{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96684e28-dc02-4293-8ea2-58f79be8fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1b34b6d-b001-4b3c-84e6-f6d50c1faeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=400, n_features=4)\n",
    "X = pd.DataFrame(X, columns=['f1', 'f2', 'f3', 'f4'])\n",
    "y = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c47c5-9d64-4d58-83bc-2135607fb875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "226d701d-c880-4067-b6ef-094a7e4dfe88",
   "metadata": {},
   "source": [
    "Нужно написать метд `.fit(X, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d190d-573f-4690-8675-43c98ba0f3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b75c91-08ee-4d78-ba29-d77e3ee57803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652fe10-2524-403c-b14e-640f813c3d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3c6b9aa1-050a-4a94-ae56-8bf219cbe58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTreeClf:\n",
    "    class Node: \n",
    "        def __init__(self, y, depth=0, idx=None): \n",
    "            self.feature = None                   # по какой фиче разделяем\n",
    "            self.threshold = None                 # порог разбиения \n",
    "            self.left = None                      # левый дочерний узел \n",
    "            self.right = None                     # правый дочерний узел \n",
    "            self.prediction = None                # значение предсказания, если это лист\n",
    "            self.is_leaf = False                  # является ли узел листом \n",
    "            self.y = y                            # таргеты, относящиеся к узлу \n",
    "            self.depth = depth                    # глубина узла \n",
    "            self.idx = idx                        # индексы строк X|y, принадлежащие к этому узлу\n",
    "            \n",
    "    def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20): \n",
    "        self.max_depth = max_depth                      # максимальная глубина дерева\n",
    "        self.min_samples_split = min_samples_split      # минимальное число элементов в листе\n",
    "        self.max_leafs = max_leafs                      # максимальное число листов дерева\n",
    "        self.leafs_cnt = 0                              # счетчик листьев дерева \n",
    "        \n",
    "    def __repr__(self): \n",
    "        return f'MyTreeClf class: max_depth={self.max_depth}, min_samples_split={self.min_samples_split}, max_leafs={self.max_leafs}'\n",
    "\n",
    "    def __entropy(self, y): \n",
    "        y = y.copy()\n",
    "        p = np.array([x/len(y) for x in np.bincount(y)])  # считаем вероятность вхождения каждого класса в сплит\n",
    "        p = p[p > 0]                                      # убираем 0 вероятности\n",
    "        return np.sum(-p*np.log2(p))\n",
    "\n",
    "    def __information_gain(self, y, y_left, y_right): \n",
    "        # Размеры выборок\n",
    "        n, n_left, n_right = len(y), len(y_left), len(y_right)\n",
    "        # Если одна из подвыборок пуста — сплит бесполезен, прирост информации равен 0\n",
    "        if n_left == 0 or n_right == 0: \n",
    "            return 0\n",
    "        # Энтропия исходной выборки (до разделения)\n",
    "        H_parent = self.__entropy(y)\n",
    "    \n",
    "        # Энтропии левой и правой подвыборок (после разделения)\n",
    "        H_left = self.__entropy(y_left)\n",
    "        H_right = self.__entropy(y_right)\n",
    "    \n",
    "        # Прирост информации = уменьшение энтропии после разбиения\n",
    "        IG = H_parent - (n_left / n) * H_left - (n_right / n) * H_right\n",
    "    \n",
    "        # Возвращаем значение прироста информации\n",
    "        return IG    \n",
    "\n",
    "    def __get_best_split(self, X, y):\n",
    "        # Создаём копии X и y, чтобы не изменять исходные данные\n",
    "        X, y = X.copy(), y.copy()\n",
    "   \n",
    "        # Глобальные переменные для хранения лучшего сплита по всему датасету\n",
    "        best_IG = -np.inf           # Максимальный прирост информации среди всех колонок\n",
    "        best_col = None             # Название колонки, по которой достигается лучший сплит\n",
    "        best_split_value = None     # Значение сплита, которое даёт этот прирост\n",
    "        \n",
    "        # Проходим по каждой колонке признаков\n",
    "        for col in X.columns: \n",
    "            # Берём уникальные значения текущей колонки и сортируем их\n",
    "            unique_values = np.sort(X[col].unique())\n",
    "        \n",
    "            # Проходим по всем парам соседних уникальных значений для формирования порогов\n",
    "            for i in range(len(unique_values)-1): \n",
    "                # Порог для сплита — среднее между двумя соседними уникальными значениями\n",
    "                split = (unique_values[i] + unique_values[i+1]) / 2  \n",
    "            \n",
    "                # Создаём булевы маски для левой и правой подвыборки\n",
    "                left_mask = X[col] <= split\n",
    "                right_mask = X[col] > split\n",
    "            \n",
    "                # Формируем соответствующие подвыборки таргета\n",
    "                y_left, y_right = y[left_mask], y[right_mask]\n",
    "\n",
    "                # Вычисляем прирост информации для текущего сплита\n",
    "                IG = self.__information_gain(y, y_left, y_right)\n",
    "            \n",
    "                # Если этот сплит даёт лучший прирост информации среди всех колонок — обновляем глобальные переменные\n",
    "                if IG > best_IG:\n",
    "                    best_IG = IG\n",
    "                    best_split_value = split\n",
    "                    best_col = col\n",
    "    \n",
    "        # Возвращаем кортеж с лучшей колонкой, значением сплита и максимальным приростом информации\n",
    "        return best_col, best_split_value, best_IG\n",
    "\n",
    "    def fit(self, X, y): \n",
    "        X, y = X.copy(), y.copy() \n",
    "        root = self.Node(y=y, depth=0, idx=X.index)\n",
    "        leafs = [root]     # cписок узлов\n",
    "        while leafs: \n",
    "            leaf = leafs.pop(-1)\n",
    "            X_leaf, y_leaf = X.loc[leaf.idx], y.loc[leaf.idx]\n",
    "\n",
    "            if (leaf.depth >= self.max_depth or\n",
    "                len(y_leaf) < self.min_samples_split or\n",
    "                len(set(y_leaf)) == 1 or \n",
    "                self.leafs_cnt + 1 >= self.max_leafs):\n",
    "                leaf.prediction = y_leaf.mean()  # самый частый класс\n",
    "                leaf.is_leaf = True \n",
    "                self.leafs_cnt += 1 \n",
    "                continue                # идем к следующему узлу \n",
    "            # находим лучший сплит для текущего узла\n",
    "            col, threshold, ig  = self.__get_best_split(X_leaf, y_leaf)  \n",
    "            # если прирост информации нулевой, делаем лист \n",
    "            if ig == 0: \n",
    "                leaf.prediction = y_leaf.mean() \n",
    "                leaf.is_leaf = True\n",
    "                self.leafs_cnt += 1 \n",
    "                continue \n",
    "            # проверяем, что хватит мества для двух новых листьев\n",
    "            if self.leafs_cnt + 2 > self.max_leafs: \n",
    "                leaf.prediction = y_leaf.mean()\n",
    "                leaf.is_leaf = True\n",
    "                self.leafs_cnt += 1 \n",
    "                continue\n",
    "            # делим данные по порогу\n",
    "            left_mask = X_leaf[col] <= threshold     \n",
    "            right_mask = X_leaf[col] > threshold\n",
    "            left_idx = X_leaf[left_mask].index\n",
    "            right_idx = X_leaf[right_mask].index \n",
    "            \n",
    "            # создаем дочерние узлы\n",
    "            left_node = self.Node(y=y.loc[left_idx], depth=leaf.depth + 1, idx=left_idx) \n",
    "            right_node = self.Node(y=y.loc[right_idx], depth=leaf.depth + 1, idx=right_idx)\n",
    "            \n",
    "            # присваиваем родителю данные сплита \n",
    "            leaf.left, leaf.right = left_node, right_node \n",
    "            leaf.feature = col \n",
    "            leaf.threshold = threshold\n",
    "            \n",
    "            # добавляем в сипсок листьев \n",
    "            leafs.append(left_node)\n",
    "            leafs.append(right_node)\n",
    "    \n",
    "        self.root = root   \n",
    "\n",
    "    def print_tree(self):\n",
    "        def _print(node, depth=0):\n",
    "            indent = \"  \" * depth  # создаём отступ в зависимости от глубины\n",
    "            if node.is_leaf:\n",
    "                print(f\"{indent}leaf = {node.prediction}\")\n",
    "            else:\n",
    "                print(f\"{indent}{node.feature} > {node.threshold}\")\n",
    "                if node.left is not None:\n",
    "                    _print(node.left, depth + 1)\n",
    "                if node.right is not None:    \n",
    "                    _print(node.right, depth + 1)\n",
    "        _print(self.root)\n",
    "\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "980f71f2-428d-4d85-9426-5883071c5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('banknote+authentication.zip', header=None)\n",
    "df.columns = ['variance', 'skewness', 'curtosis', 'entropy', 'target']\n",
    "X, y = df.iloc[:,:4], df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1725b-4992-4503-8702-9e72faf01972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d55c5ba7-db15-45dd-ae25-0cc0cff21f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_1 = MyTreeClf(max_depth=1, min_samples_split=1, max_leafs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9613a83b-74cf-4795-920b-a238322f69c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyTreeClf class: max_depth=1, min_samples_split=1, max_leafs=2"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "39186545-c003-49e5-b43f-9e2ecf943dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b4949075-3c8f-49d3-8556-8b2e05b22076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance > 0.320165\n",
      "  leaf = 0.8112633181126332\n",
      "  leaf = 0.1076923076923077\n"
     ]
    }
   ],
   "source": [
    "tree_1.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f664a77c-af58-4086-9af4-ff9a2329d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.leafs_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fc704-e698-45fe-9f34-acf87931cdee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "01ca8933-c42d-4451-b3d4-6a5aa49640f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_2 = MyTreeClf(max_depth=3, min_samples_split=2, max_leafs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "05acc12b-328e-4d6d-8b07-18c89b213282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyTreeClf class: max_depth=3, min_samples_split=2, max_leafs=5"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "55ea90e2-be18-4966-8c84-32db7b47b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "86879a87-d4f2-4687-838b-18d7808ddb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance > 0.320165\n",
      "  leaf = 0.8112633181126332\n",
      "  variance > 1.7907000000000002\n",
      "    curtosis > -2.2721999999999998\n",
      "      leaf = 0.9473684210526315\n",
      "      leaf = 0.10227272727272728\n",
      "    curtosis > -4.802\n",
      "      leaf = 0.6\n",
      "      leaf = 0.0041928721174004195\n"
     ]
    }
   ],
   "source": [
    "tree_2.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668d313-e722-45e3-8954-73cedd294ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
